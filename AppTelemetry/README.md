![Image](https://www.rti.com/hubfs/RTI_Oct2016/Images/rti-logounit.png)

RTI Connext DDS Use Case:
Including Application Telemetry alongside RTI's Observability Platform
=======================================================================
  
##  Introduction

Application telemetry refers to the collection, monitoring, and analysis of data generated by an application during its operation. This data provides critical insights into an application's performance, usage patterns, and potential issues, enabling developers and operators to optimize functionality, diagnose problems, and ensure reliability. Telemetry is essential for understanding the health and efficiency of modern distributed systems, where real-time visibility into application-level behavior is a cornerstone of successful system management.

Telemetry data can be generated at three different levels:
* Application: Telemetry data generated when you instrument your own applications.
* Middleware: Telemetry data generated by Connext DDS entities and infrastructure services.
* System: DevOps telemetry such as CPU, memory, and disk I/O usage.

[RTI® Connext® Observability Framework](https://community.rti.com/static/documentation/connext-dds/current/doc/manuals/addon_products/observability/index.html) is a holistic solution that uses telemetry data to provide deep visibility into the current and past states of your Connext applications. This visibility makes it easier to proactively identify and resolve potential system issues, providing a higher level of confidence in the reliable operation of the system.

At the time of writing, RTI's Observability Framework supports middleware telemetry (metrics and logs) and application logs only. While visibility into the middleware is of great value, it would be beneficial to be able to capture and include application-level metrics in the dashboards.

This example details the process of creating an adapter for [RTI's Routing Service](https://community.rti.com/static/documentation/connext-dds/current/doc/manuals/connext_dds_professional/services/routing_service/index.html) to collect application-level metrics published on a DDS topic. The adapter will transform and expose this telemetry data in a format compatible with Prometheus, a widely-used open-source monitoring system. Additionally you will learn how to visualize the application-level metrics alongside Connext DDS telemetry in a Grafana dashboard, enabling a unified and comprehensive monitoring experience.

  

Through this guide, you will learn to:
1. Develop a custom Routing Service adapter for application telemetry.
2. Configure Prometheus to scrape and display application telemetry data.
3. Integrate application telemetry into Grafana for a combined view with Connext telemetry.

By the end, you'll have a robust solution for monitoring both DDS system performance and application-level insights, helping you maximise the value of your telemetry data.

##  Cloning the repository

To clone the repository you will need to run git clone as follows to download both the repository and its submodule dependencies:

To clone the [GitHub repository](https://github.com/rticommunity/rticonnextdds-usecases.git) containing this use case, you will need to run git clone as follows to download both the repository and its submodule dependencies:  

```bash
git clone --recurse-submodule  
https://github.com/rticommunity/rticonnextdds-usecases.git
```
If you forget to clone the repository with --recurse-submodule, simply run the following command to pull all the dependencies:
```bash
git  submodule  update  --init  --recursive
```

## Repository layout
The respository is organised as follows:

```bash
├── CMakeLists.txt                   # This is the CMake file for OpenTelemetry C++ (downloaded by dockerfile), the Routing Service adapter and the generator
├── Dockerfile                       # The Dockerfile which tells docker how to build the container image
├── generator                        # The source code for the generator project, including the datamodel idl and the QoS file
│   ├── c++11
│   │   ├── application.hpp
│   │   ├── generator.cxx
│   │   └── generator_qos.xml
│   └── telemetry.idl
├── LICENCE                          # The licence for the repository
├── README.md                        # This file
├── resource                         
│   ├── cmake                        # Additional resources required for cmake
│   └── img                          # Image file used in this document
└── src                              # The source code for the Routing Service adapter, requires OpenTelemetry C++ to compile
    ├── oteladapter.cxx
    ├── oteladapter.hpp
    ├── otelconfig.hpp
    ├── otelconnection.cxx
    ├── otelconnection.hpp
    ├── otelstreamwriter.cxx
    ├── otelstreamwriter.hpp
    ├── RsTelemetryGateway.xml      # The Gateway configuration
    └── run_tmux.sh                 # Helper script to run both applications simultaneously in a single docker terminal window
```



##  Build Docker image

This example is encapsulated inside a Docker container for convenience, and once the repository has been cloned, the next step is to configure a Docker image. During the image build process, the applications included in this example will be automatically compiled and included inside the Docker image. These applications and the sources will be accessible in the resulting image at the /root/ directory. This results in a sandbox which allows you to explore, modify and build the code as desired without tainting the host system with library sources and build artefacts.

To create the docker image adjust the line in the Dockerfile that reads ENV TZ=Europe/Madrid to set the correct timezone, then run the following command to build the Connext image for the 7.3.0 release, take into account that you are accepting the RTI license agreement by setting the RTI_LICENSE_AGREEMENT_ACCEPTED argument to "accepted":

```bash
docker build -t connext:oteladapter -f ./Dockerfile --build-arg RTI_LICENSE_AGREEMENT_ACCEPTED=accepted --build-arg CONNEXT_VERSION=7.3.0 .
```

If you want to target a different version of Connext, then you must set the following arguments to match your requirements    
- CONNEXT_VERSION: supported values are 7.3.0 and 6.1.2  
  
Here's an example of what that would look like for a 6.1.2 release:  
```bash
docker build -t connext:6.1.2 -f docker/Dockerfile --build-arg RTI_LICENSE_AGREEMENT_ACCEPTED=accepted --build-arg CONNEXT_VERSION=6.1.2 .
```

#  Running the example 
## Starting the Docker Container
 To run the Docker container, run the following command:

```bash
docker run -it --rm --net=host -v $RTI_LICENSE_FILE:/root/rti_license.dat:ro connext:oteladapter
```

### Here’s what those parameters mean:
- run: run container
- -i: Interactive
- -t: Allocate pseudo-TTY
- --rm: Automatically remove the container when it exits
- –net: Define which docker network to use, in this case the container shares its network namespace with the host machine
- -v: Bind mount a volume, this line ensures that the local Connext license appears inside the Docker container as a read-only file


A valid RTI Connext license is required to execute Connext within the containers, you can download a fully functional Connext evaluation license [here](https://www.rti.com/free-trial). To set the required environment variable `RTI_LICENSE_FILE`, in the terminal from which you start the docker containers, run:
```bash
export RTI_LICENSE_FILE=/path/to/rti_license.dat
```

## Executing the example
Once the container is started and you are at the terminal prompt, change directory to the `opentelemetry-adapter/build` directory. From there you can execute the run_tmux.sh script which will create a tmux session, split the window two panes and starts the two parts of the demo:

![tmux session](resource/img/tmux.png)

The Prometheus Gateway is in the top pane, and the Generator can be seen running in the lower pane. You can switch between the two panes to control them.
###  Switching Panes in tmux

To switch between panes in a [tmux](https://github.com/tmux/tmux/wiki/Getting-Started) session, you can use the following keyboard shortcuts:

-  `Ctrl-b` followed by `o`: Move to the next pane.

-  `Ctrl-b` followed by an arrow key (`←`, `→`, `↑`, `↓`): Move to the pane in the specified direction.

-  `Ctrl-b` followed by `;`: Move to the previously active pane.

These shortcuts allow you to navigate efficiently between different panes within your tmux session.
  
# How the example was developed

## Step 1: Define the data model

The first challenge is to come up with [a data model](generator/telemetry.idl) that reflects our needs: routing telemetry data to Prometheus via DDS. The most straight-forward way would be to establish a data model which defines a set of metrics and their associated data structures which can be easily mapped to OpenTelemetry concepts. The use of `@appendable` annotations ensures extensibility, allowing the model to evolve without breaking compatibility, which is crucial for observability frameworks like OpenTelemetry.

### Main structure
There are various types of metric that we might want to support along with descriptive data. So let's define that first:

```c
@appendable
struct  Metric {
    @key MetricName name; 
    MetricDescription description;
    @key MetricUnit unit; 
    MetricUnion data;
    @optional sequence<Label> labels;
};
```
This struct is designed to represent a metric with a unique name and unit, a description, data, and optional labels. The use of key fields ensures that each metric can be uniquely identified, and the appendable annotation allows for future extensions.

### Type definitions
The next step is to define the types we envisaged for the main struct:

 - **`MetricName`**: A string with a maximum length of 256 characters, in OpenTelemetry this represents the name of a metric, such as "http_requests_total" or "cpu_usage".

-  **`MetricDescription`**: A string with a maximum length of 512 characters, this provides a human-readable description of the metric, explaining its purpose or usage.

-  **`MetricUnit`**: A string with a maximum length of 64 characters, this specifies the unit of measurement for the metric (e.g., "seconds", "bytes", "requests").

- **`MetricUnion`**: This is a union of all the types of metric.

- **`Label`**: A sequence of labels, this represent the keys and values of labels (or attributes) associated with the metrics. Labels provide additional context, such as "region=us-west" or "status=200", or metric quality, i.e. "status=good" or "status=warning"

### Structs

#### Label
A label consists of a LabelKey and a LabelValue, both are strings with a maximum length of 256 characters. Represents a single label (attribute) key-value pair.

```c
typedef string<256> LabelKey;
typedef string<256> LabelValue;
struct Label {
    LabelKey key;
    LabelValue value;
};
```

#### MetricUnion

The MetricUnion switches between different metric types (`UInt64Counter`, `DoubleCounter`, `UInt64Histogram`, `DoubleHistogram`, `UInt64UpDownCounter`, `DoubleUpDownCounter`, `Int64Gauge`, and `DoubleGauge`). This represents a polymorphic metric type, allowing a single metric to be one of several types. This is similar to how OpenTelemetry supports multiple metric types under a unified API.

##### Members

-  **`UInt64Counter` and `DoubleCounter`**: The `value`field represents the counter value. These correspond to counter metrics, which are used to represent a cumulative value that only increases (e.g., total requests served).
-  **`UInt64Histogram` and `DoubleHistogram`**: The `labels` field is a sequence of `Label` structs. and the`buckets` field is a sequence of bucket values (either `uint64` or `double`). This maps in OpenTelemetry to histogram metrics, which are used to measure the distribution of values (e.g., request latency). The `labels` provide context, and the `buckets` define the histogram's distribution.
-  **`UInt64UpDownCounter` and `DoubleUpDownCounter`**: The `value`field represents the counter value. These correspond to up-down counters, which can increase or decrease (e.g., active connections).
- **`Int64Gauge` and `DoubleGauge`**: The `value`field represents the counter value and these correspond to OpenTelemetry gauges, which can increase or decrease (e.g., available RAM). These are only available if the OpenTelemetry C++ Library is compiled with the ABI version as 2 or above (default)
---
## Step 2: Create the Adapter  
A Routing Service adapter is a pluggable component in the [RTI Routing Service](https://community.rti.com/static/documentation/connext-dds/current/doc/manuals/connext_dds_professional/services/routing_service/index.html) that enables the service to interact with different data domains. These adapters are designed to consume and produce data from various sources, such as DDS, MQTT, sockets, files, and more. They act as a bridge between the Routing Service and the specific data domain, allowing data to flow seamlessly between them.

Adapters are responsible for:
* Input Adapters: Collecting data samples from a data domain and passing them to the Routing Service engine.
* Output Adapters: Sending data from the Routing Service to a data domain, potentially applying transformations beforehand.

The adapter architecture supports custom implementations, enabling developers to create adapters tailored to their specific integration needs. For example, a file adapter can read data from a file and send it to a DDS domain, or vice versa.

In this example, we've created an Output Adapter using [OpenTelemetry C++](https://opentelemetry.io/docs/languages/cpp/) which provides data to [Prometheus](https://prometheus.io/) through its Prometheus Exporter, which enables metrics collected by the OpenTelemetry SDK to be scraped by Prometheus.

The first step is to initialise and configure the Prometheus Exporter in the adapter application. This involves creating an instance of the exporter and setting up the endpoint where metrics will be exposed. This is performed in [otelconnextion.cxx](src/otelconnection.cxx) where the properties required for the endpoint are read from the routing service Quality of Service definition. When the routing service asks the adapter to provide a stream writer, the adapter returns an instance of the OpenTelemetryStreamWriter class. This class' main function, write, takes a collection of samples and using the Dynamic Data API, determines the correct OpenTelemetry C++ type to create from the sample and converts the data contained in the sample to an OpenTelemetry metric.
  

## Step 3: Configuration of the Routing Service

The included [Routing Service configuration](src/RsTelemetryGateway.xml) is an XML file that defines a setup for integrating OpenTelemetry with RTI Connext DDS. It sets up an RTI Routing Service instance named `OpenTelemetryGateway` to integrate with OpenTelemetry using a the adapter plugin. It defines:

- Configuration variables for scraping metrics and enabling debug logging.
- A plugin library (`AdapterLib`) with an adapter plugin (`OpenTelemetryAdapter`) for OpenTelemetry integration.
- A domain route (`DDSOtel`) with a connection (`OpenTelemetryConnection`) that uses the adapter plugin.

This setup is designed to enable the collection and export of telemetry data from RTI Connext DDS to Prometheus.

---
###  **Configuration Variables: `<configuration_variables>`**
This section defines variables that can be used throughout the configuration.

-  **`SCRAPE_URL`**:  **Value**: `0.0.0.0:9464`,  specifies the URL where metrics can be scraped. This is used for exposing metrics in a Prometheus-compatible format.
- **`EXPORT_DEBUG`**:    **Value**: `true`,  enables debug-level logging for exporting metrics. This is useful for troubleshooting and verifying the integration.

###  **Plugin Library: `<plugin_library>`**

This section is where the custom adapter plugin is defined for the Routing Service.
-  **`name="AdapterLib"`**: The name of the plugin library.

###  **Adapter Plugin: `<adapter_plugin>`**
This section defines the location of the adapter library which is responsible for integrating OpenTelemetry with the Routing Service, enabling the collection and export of telemetry data, and the entry point.
-  **`name="OpenTelemetryAdapter"`**: The name of the adapter plugin.
-  **`<dll>`**: Specifies the shared library (`oteladapter`) that implements the adapter.
-  **`<create_function>`**: Specifies the function (`OpenTelemetryAdapter_create_adapter_plugin`) used to create an instance of the adapter plugin.
  
###  **Routing Service: `<routing_service>`**
This section defines the Routing Service instance, this connection establishes the link between DDS and OpenTelemetry, enabling data to flow between the two systems.

-  **`name="OpenTelemetryGateway"`**: The name of the Routing Service instance.
-  **Domain Route: `<domain_route>`**
   -  **`name="DDSOtel"`**: The name of the domain route, which connects DDS with OpenTelemetry.
-  **Connection: `<connection>`**
   -  **`name="OpenTelemetryConnection"`**: The name of the connection.
   -  **`plugin_name="AdapterLib::OpenTelemetryAdapter"`**: Specifies the plugin to use for this connection. It references the `OpenTelemetryAdapter` previously defined.

 
## Step 4: Generate test data  
The generator is a basic Connext application that publishes random data for each metric type supported by the adapter: counter, histogram, up-down counter, and gauge (if the OpenTelemetry C++ Library is compiled with the ABI version 2). It cycles through these types, assigning random values or initialising from a random starting point.

This enables testing of various metric types while providing the adapter with data to validate Prometheus and Grafana configurations seamlessly.

###  Executing the generator :
The generator needs a Quality of Service file defined to execute. All the other parameters, such as domain, sample count and verbosity will default to predefined values.

- -d, --domain <int> Domain ID this application will participate in. Default: 2
- -q, --qos_file <str> XML file containing QoS profiles for the application. This is required
- -s, --sample_count <int> Number of samples to receive before cleanly shutting down. Defaults to *infinite*
- -v, --verbosity <int> How much debugging output to show. Range: 0-3 Default: 1
  
The generator can be executed from a docker container terminal window, by changing directory to ```/root/opentelemetry-adapter/build``` and running ```./generator -d 2 -q generator_qos.xml```

  
## Step 5:  Executing the RTI Routing Service with the OpenTelemetry plugin
From a docker container terminal window, change directory to ```/root/opentelemetry-adapter/build``` and run ```rtiroutingservice -cfgFile ./RsTelemetryGateway.xml -cfgName "OpenTelemetryGateway"```

This command is used to start the RTI Routing Service with the included configuration file and specific configuration name.

- ```rtiroutingservice``` is the executable for the RTI Routing Service. It is used to start the service.
- ```-cfgFile``` specifies the XML configuration file to use for the Routing Service, in this case ```./RsTelemetryGateway.xml``` which is the included configuration and contains the configuration for the Routing Service, including domain routes, connections, and plugins.
- ```-cfgName "OpenTelemetryGateway"``` starts the RTI Routing Service using the named configuration defined in the [RsTelemetryGateway.xml](src/RsTelemetryGateway.xml) file, specifically the configuration named OpenTelemetryGateway within that file.
    

##  Step 4+5: Running the Router & Generator at the same time using tmux

To facilitate running two commands at the same time in a single Docker terminal window, the docker container includes **[tmux](https://github.com/tmux/tmux/wiki)** and a script which will start tmux, create two panes and run the routing service in the first (pane 0), and the generator in the second (pane 1).

###  Starting the tmux session
From a docker container terminal window, change directory to ```/root/opentelemetry-adapter/build``` and execute ```./run_tmux.sh```

###  Switching between the panes
To switch between panes in a tmux session, you can use the following keyboard shortcuts:
-  `Ctrl-b` followed by `o`: Move to the next pane.
-  `Ctrl-b` followed by an arrow key (`←`, `→`, `↑`, `↓`): Move to the pane in the specified direction.
-  `Ctrl-b` followed by `;`: Move to the previously active pane.
  
###  Exit or Detach from the session
- To **detach** the tmux session and leave it running in the background, press `Ctrl-b` followed by `d`.
- To **exit** a window, type `exit` in the window.

  
###  Reattaching to the session

- To **attach** the tmux session either re-run the ```run_tmux.sh``` script or type ```tmux attach -t OtelAdapter```.


##  Step 6: Configuration of Prometheus

###  Integration with RTI Observability Platform
 
Before completing this section, you'll need to have the RTI Observability Platform installed and configured. See [the installation instructions](https://community.rti.com/static/documentation/connext-dds/current/doc/manuals/addon_products/observability/install.html) to find out how to do that.

###  Prometheus Configuration

Add a new job to the Observability platform's Prometheus configuration in {$HOME}/rti_workspace/7.3.0/user_config/observability/prometheus/prometheus.yml

Configuration options can be set in the `config.json` file. Below is an example configuration:

```yaml
scrape_configs:
#
# Configuration for Prometheus exporter in a system
#
# The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
#
- job_name: 'prometheus'
 
# metrics_path defaults to '/metrics'
# scheme defaults to 'http'.
  
static_configs:
- targets:
- localhost:9090  # Prometheus metrics
- job_name: 'routing_service'

static_configs:
- targets:
- localhost:9464  # Application metrics provided by the routing service adapter - must match the url defined in the adapter configuration
```

The second `static_configs` entry is the endpoint provided by the Routing Service adapter.

Save and (re)start the RTI Observability platform:

```bash
rtiobservability  -t && rtiobservability  -i
```
and navigate in a web-browser to [the local Prometheus UI](http://localhost:9090), click on "Status" in the menu bar, then "Targets". You should see a list of all the scrape targets, including the Routing Service Adapter scrape target

![Image showing inclusion of target](resource/img/prometheus_target.png  "Prometheus Target")

Clicking on the Endpoint, will open the [webpage provided by the adapter](http://localhost:9464/metrics) showing the raw metric data that Prometheus will scrape
 
### Grafana Configuration

Here’s a step-by-step guide and an example of adding Prometheus-provided metrics to a Grafana dashboard. There are some very helpful tutorials on the [Grafana website](https://grafana.com/tutorials/):  

####  **Grafana Step 1: Login to Grafana**
Open Grafana in your browser, if you are using the RTI Observability Framework, the address should be http://localhost:3000/ and log in.

####  **Grafana Step 2: Create a New Dashboard** 
In the Grafana menu, click **Dashboards > New Dashboard**, then choose **Add visualization**.

####  **Grafana Step 3: Query Prometheus for Metrics**

In the **Query** section of the panel editor:
- Set the **Data Source** to Prometheus.
- Enter your Prometheus query in the **Metric** field or open the **Metrics Explorer** (e.g., all the generator metrics begin with the name `rti_example`).
- Click **Run Query** to see the result preview.

Example Prometheus Queries:
-  **`prometheus_http_requests_total`**: Total number of HTTP requests.
-  **`rate(rti_example_double_counter_Micro_Fortnight_total[1m])`**: Per-second rate of Micro-Fortnights provided by the generator over the last minute.
-  **`up`**: Checks whether a target is up and running.

####  **Grafana Step 4: Configure Visualization**
-  **Visualization Type**:  Choose the type of graph or chart you want (e.g., Time series, Gauge, Bar graph). This option is available in the **Visualization** tab of the panel editor.
- **Panel Options**: Configure titles, units, thresholds, and other display settings.

Some of the metrics provided by the generator use textual labels like `status="good"`, `status="warning"`, `status="error"`. These can be mapped to show specific colors. To do this, in the **Overrides** tab, click **"Add field override"** → Select **"Fields with name"** and choose the metric name.

Under **"Value Mappings"**, click **"Add value mapping"** and define:
-  `good` → Green
-  `warning` → Yellow
-  `error` → Red

![Prometheus Overrides](resource/img/prometheus_overrides.png)

There are many more options available for customisations and transformations based on the label contents.

####  **Grafana Step 5: Save the Dashboard**
Once you’re satisfied with the configuration, click **Apply**. Then save the dashboard with a meaningful name.
  
#### WARNING
If the Observability Framework is removed, ie by running ```rtiobservability -d```, this removes all changes to your current Observability Framework Docker environment including:
* metric data in Prometheus
* log data in Loki
*  **all Grafana user and dashboard configurations**

## Optional: Connect to the container with Visual Studio Code

You can edit the code from the repository, and rebuild the docker image to test it, but that results in a long cycle to test changes. A more convenient way is to connect to the container from Visual Studio Code, make the changes, build and test directly inside the docker container.

If you haven’t already got Visual Studio Code installed, download it from [code.visualstudio.com](code.visualstudio.com) 

### Extensions
To make best use of the integrations, install the [Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) and [Docker](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker) extensions. You may also want to install C++ and CMake extensions once you have the IDE connected to the container.

### Connect to the container

Open the Command Palette (Ctrl+Shift+P) and select **Dev Containers: Attach to Running Container**

From the drop-down select the running container, `connext:oteladapter` and a new Visual Studio Code window will appear, and you will be able to see the browse the example code and configuration in the explorer sidebar. If desired you can also open a terminal window with VSCode, to execute build commands and/or run the resulting executables.

![Visual Studio Code connected to the docker container ](resource/img/vscode.png)

##  License

See the [LICENCE](LICENCE) file for details.
